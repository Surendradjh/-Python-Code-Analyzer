{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\vempa\\OneDrive\\Desktop\\Innomatix lab\\Internship\\gen_ai\\api.txt\",'rb') as f:\n",
    "    key=f.read()\n",
    "\n",
    "\n",
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "for i in genai.list_models():\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "for i in range(n):\n",
      "    print(i)\n",
      "```\n",
      "\n",
      "Error line: 1\n",
      "Error type: SyntaxError: invalid syntax\n",
      "\n",
      "Output:\n",
      "```\n",
      "name 'n' is not defined\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# system_instruction=\"Take python code as input ,analyse and return the corrected code with out any explanation\"# expling where the error was raised\"\n",
    "system_instruction=\"Take python code as input ,analyse and return the corrected code with out any explanation.tell me which line the error was occored and what error that was and return the output of that code\"\n",
    "\n",
    "model=genai.GenerativeModel(model_name='models/gemini-2.0-flash-thinking-exp-1219',system_instruction=system_instruction)#\"Act like a python code analyser and return the corrected output based on the input explaining with each error line\")\n",
    "prompt=\"\"\"for i in is n:\n",
    "            println(i)\n",
    "\"\"\"\n",
    "a=model.generate_content(prompt).text\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```python\\nfor i in range(n):\\n    print(i)\\n```\\n\\nError line: 1\\nError type: SyntaxError: invalid syntax\\n\\nOutput:\\n```\\nname 'n' is not defined\\n```\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # with open(\"Python_Code_analyzer.pkl\",'wb') as file:\n",
    "# #     pickle.dump(model,file)\n",
    "\n",
    "# with open(\"Python_Code_analyzer.pkl\", 'wb') as file:\n",
    "#     pickle.dump(model, file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
